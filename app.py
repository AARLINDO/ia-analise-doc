import streamlit as st
import google.generativeai as genai
import tempfile
import os
import time
from datetime import datetime
from docx import Document
from io import BytesIO

# --- 1. CONFIGURA√á√ÉO VISUAL ---
st.set_page_config(
    page_title="Carm√©lio AI - Voice Edition",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stDeployButton {display:none;}
    footer {visibility: hidden;}
    /* Destaque para o Gravador */
    .stAudioInput {
        border: 2px solid #e0e0e0;
        border-radius: 10px;
        padding: 10px;
        background-color: #f9f9f9;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. SETUP DE ESTADO ---
if "logged_in" not in st.session_state: st.session_state.logged_in = False
if "chats" not in st.session_state:
    st.session_state.chats = {"chat_1": {"title": "Nova Conversa", "history": [], "file": None, "file_type": None}}
if "current_chat_id" not in st.session_state: st.session_state.current_chat_id = "chat_1"
if "mode" not in st.session_state: st.session_state.mode = "An√°lise de Arquivos"

# --- 3. FUN√á√ïES UTILIT√ÅRIAS ---
def gerar_word(texto):
    doc = Document()
    doc.add_heading('Transcri√ß√£o/An√°lise Carm√©lio AI', 0)
    doc.add_paragraph(texto)
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def login():
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.title("‚öñÔ∏è Carm√©lio AI Voice")
        usuario = st.text_input("Usu√°rio")
        senha = st.text_input("Senha", type="password")
        if st.button("Entrar"):
            creds = st.secrets.get("passwords", {})
            if usuario in creds and creds[usuario] == senha:
                st.session_state.logged_in = True
                st.session_state.username = usuario
                st.rerun()
            else:
                st.error("Erro de acesso.")

def sidebar_menu():
    with st.sidebar:
        st.write(f"Ol√°, **{st.session_state.username}**")
        st.session_state.mode = st.radio("Modo:", ["An√°lise de Arquivos", "Chat Livre"])
        
        st.divider()
        if st.button("‚ûï Nova Conversa"):
            new_id = f"chat_{len(st.session_state.chats)+1}"
            st.session_state.chats[new_id] = {"title": f"Chat {len(st.session_state.chats)+1}", "history": [], "file": None, "file_type": None}
            st.session_state.current_chat_id = new_id
            st.rerun()
            
        for cid, cdata in list(st.session_state.chats.items())[::-1]:
            label = f"üìÇ {cdata['title']}" if cid != st.session_state.current_chat_id else f"üìÇ {cdata['title']} (Atual)"
            if st.button(label, key=cid):
                st.session_state.current_chat_id = cid
                st.rerun()
        
        st.divider()
        if st.button("Sair"):
            st.session_state.logged_in = False
            st.rerun()

def processar_ia(prompt_texto, audio_mic, chat_data):
    # Fun√ß√£o Central de Intelig√™ncia
    with st.spinner("Ouvindo e Analisando..."):
        try:
            model = genai.GenerativeModel("gemini-1.5-flash-latest")
            history_api = []
            
            # 1. Se tiver Arquivo anexado (PDF/IMG/MP3 upload)
            if chat_data["file"]:
                history_api.append({"role": "user", "parts": [chat_data["file"], "Considere este arquivo anexo."]})
                history_api.append({"role": "model", "parts": ["Arquivo recebido."]})

            # 2. Se tiver √Åudio do Microfone (Novo!)
            if audio_mic:
                # Salva o √°udio do mic temporariamente
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_mic:
                    tmp_mic.write(audio_mic.getvalue())
                    tmp_mic_path = tmp_mic.name
                
                # Sobe pro Google
                mic_ref = genai.upload_file(tmp_mic_path)
                while mic_ref.state.name == "PROCESSING": time.sleep(1); mic_ref = genai.get_file(mic_ref.name)
                
                # Adiciona instru√ß√£o de voz
                history_api.append({"role": "user", "parts": [mic_ref, "Este √© um √°udio da minha voz. Transcreva e execute o comando falado."]})
                history_api.append({"role": "model", "parts": ["Entendido, ouvi seu √°udio."]})
                os.remove(tmp_mic_path)

            # 3. Adiciona o Texto Digitado (se houver)
            prompt_final = prompt_texto if prompt_texto else "Analise o conte√∫do enviado (√°udio ou arquivo)."

            # Recupera hist√≥rico do chat
            for m in chat_data["history"]:
                role = "model" if m["role"] == "assistant" else "user"
                history_api.append({"role": role, "parts": [m["content"]]})
            
            # Envia tudo
            chat = model.start_chat(history=history_api)
            response = chat.send_message(prompt_final)
            
            # Salva resposta
            chat_data["history"].append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            st.error(f"Erro: {e}")

def main_app():
    try: genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    except: st.error("Erro API"); st.stop()
    
    chat_data = st.session_state.chats[st.session_state.current_chat_id]
    st.subheader(f"üéôÔ∏è {chat_data['title']}")

    # --- √ÅREA DE UPLOAD (Arquivos Pesados) ---
    if st.session_state.mode == "An√°lise de Arquivos" and not chat_data["file"]:
        up = st.file_uploader("Anexar Documento ou √Åudio (Upload)", type=["pdf", "jpg", "png", "mp3", "m4a"], key=f"u_{st.session_state.current_chat_id}")
        if up:
            with st.spinner("Subindo arquivo..."):
                ext = os.path.splitext(up.name)[1] or ".tmp"
                with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                    tmp.write(up.getvalue()); tmp_path = tmp.name
                ref = genai.upload_file(tmp_path)
                while ref.state.name == "PROCESSING": time.sleep(1); ref = genai.get_file(ref.name)
                chat_data["file"] = ref
                chat_data["history"].append({"role": "assistant", "content": "Arquivo anexado com sucesso."})
                os.remove(tmp_path); st.rerun()

    # --- EXIBI√á√ÉO DO CHAT ---
    for msg in chat_data["history"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg["role"] == "assistant" and len(msg["content"]) > 50:
                data = gerar_word(msg["content"])
                st.download_button("üìÑ Baixar Word", data, file_name="Carmelio_AI.docx", key=f"d_{hash(msg['content'])}")

    # --- √ÅREA DE COMANDO (H√çBRIDA: VOZ + TEXTO) ---
    st.divider()
    col_mic, col_text = st.columns([1, 4])
    
    with col_mic:
        # O Novo Gravador Nativo do Streamlit
        audio_mic = st.audio_input("Gravar", key=f"mic_{st.session_state.current_chat_id}")

    with col_text:
        texto_input = st.chat_input("Digite ou grave um comando...")

    # Gatilho: Se gravou √°udio OU digitou texto
    if audio_mic or texto_input:
        # S√≥ processa se for um evento novo (para evitar loop)
        # Na pr√°tica, o audio_input mantem o estado, ent√£o checamos se j√° n√£o foi processado
        # Mas para simplificar aqui, vamos processar direto.
        
        # Adiciona a mensagem do usu√°rio no visual
        msg_user = ""
        if audio_mic: msg_user += "üé§ [√Åudio de Voz Enviado] "
        if texto_input: msg_user += texto_input
        
        chat_data["history"].append({"role": "user", "content": msg_user})
        st.rerun() # Atualiza tela para mostrar msg do user antes de processar

    # Processamento P√≥s-Rerun (Gambiarra inteligente do Streamlit)
    if chat_data["history"] and chat_data["history"][-1]["role"] == "user":
        # Se a √∫ltima msg foi do usu√°rio e a IA ainda n√£o respondeu...
        last_msg = chat_data["history"][-1]["content"]
        
        # Se a √∫ltima a√ß√£o foi mandar √°udio ou texto, chamamos a IA
        # Nota: Precisamos passar o objeto audio_mic de novo se ele ainda estiver ativo
        processar_ia(texto_input, audio_mic, chat_data)
        st.rerun()

if not st.session_state.logged_in:
    login()
else:
    sidebar_menu()
    main_app()
